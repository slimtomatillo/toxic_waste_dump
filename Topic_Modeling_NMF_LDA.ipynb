{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling on Harmful Comments with LDA and NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset data to harmful comments only\n",
    "data = data[data.harmful == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = data['model_text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long are the comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of words in a toxic comment is: 27\n"
     ]
    }
   ],
   "source": [
    "# Find average length of quotes by word and by characters\n",
    "# Initialize count lists\n",
    "word_length = []\n",
    "\n",
    "# Iterate through each quote and find lengths\n",
    "for comment in comments:\n",
    "    word_length.append(len(comment.split(' ')))\n",
    "    \n",
    "# Calculate means\n",
    "word_mean = int(round(np.mean(word_length)))\n",
    "\n",
    "# View averages\n",
    "print('The average number of words in a toxic comment is:', word_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Topic Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    \"\"\"\n",
    "    *Source: Aneesha Bakharia, \n",
    "    https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730\n",
    "    \n",
    "    Function that takes in a model, feature_names,\n",
    "    and no_top_words and displays topics and top\n",
    "    words in a readible fashion.\n",
    "    \n",
    "    :param: model: sklearn.decomposition\n",
    "    :param: feature_names: list\n",
    "    :param: no_top_words: int\n",
    "    \n",
    "    :returns: printed topics and top words\n",
    "    \"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of features\n",
    "no_features = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF using tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(comments)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Set number of topics\n",
    "no_topics = 6\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "fuck asshole shut cunt faggot hey want mother bitch fuckin\n",
      "\n",
      "Topic 1:\n",
      "like wikipedia page people know stop talk article stupid think\n",
      "\n",
      "Topic 2:\n",
      "fucking cunt faggot asshole mother moron retard life idiot hope\n",
      "\n",
      "Topic 3:\n",
      "suck dick cock balls hey asshole big bitch cunt ass\n",
      "\n",
      "Topic 4:\n",
      "shit bitch ass piece little eat son faggot fuckin hell\n",
      "\n",
      "Topic 5:\n",
      "gay fag faggot sex ass ur im homosexual like likes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "no_top_words = 10\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(comments)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "# Set number of topics\n",
    "no_topics = 10\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "hate ass cock fag sex yourselfgo lick nice lmao nl33ers\n",
      "\n",
      "Topic 1:\n",
      "sucks nipple stupid penis huge faggots love dickhead vandalism wiki\n",
      "\n",
      "Topic 2:\n",
      "fuck shit bitch shut piece fucking fuckin bitches cocksucking admins\n",
      "\n",
      "Topic 3:\n",
      "nigger faggot aids cunt eat wiki equalsequalsequalsequals loser noobs cuntbag\n",
      "\n",
      "Topic 4:\n",
      "like people know article wikipedia think time life admin fucking\n",
      "\n",
      "Topic 5:\n",
      "wikipedia page die bullshit dont asshole talk block pig care\n",
      "\n",
      "Topic 6:\n",
      "suck hi fucking dick dog bastard know mother balls pussy\n",
      "\n",
      "Topic 7:\n",
      "gay moron equalsequals fucker bark cocksucker super mothjer like homo\n",
      "\n",
      "Topic 8:\n",
      "fat jew buttsecks bush want poop retarded god fack chicken\n",
      "\n",
      "Topic 9:\n",
      "idiot freedom old hey damn im rape like hitler hope\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "no_top_words = 10\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
